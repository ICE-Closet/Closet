### Description of codes ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€
1. SmallerVGGNet : ì‚¬ìš©í•  Keras ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ì´ë‹¤.
2. How to quickly build a deep learning image? Bing Image Search API(Microsoft)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.<br>
    2-1. ì•„ë˜ ë§í¬íƒ€ê³  ë“¤ì–´ê°€ì„œ  Bing Image Search APIì˜ GET API KEY ìˆ˜í–‰í•˜ê¸° <br>
     ğŸ‘‰[APIì„¤ì •](https://azure.microsoft.com/en-us/try/cognitive-services/?api=bing-image-search-api) <br>
    2-2. ì•„ë˜ ëª¨ë“ˆ ì„¤ì¹˜í•˜ê¸°í•˜ê³  ì½”ë“œ ì‹¤í–‰!( ë‚˜ë¨¸ì§€ëŠ” API ì‚¬ìš© ë°©ë²• )
            
            $ pip install requests
            
            from requests import exceptions
            import argparse
            import requests
            import cv2
            import os
            # construct the argument parser and parse the arguments
            ap = argparse.ArgumentParser()
            ap.add_argument("-q", "--query", required=True, help="search query to search Bing Image API for") #ì¿¼ë¦¬ëŠ” "í”¼ìº¬ì¸„"ì´ë ‡ê²Œ ì…ë ¥
            ap.add_argument("-o", "--output", required=True, help="path to output directory of images") #ë‚´ê°€ datasetì €ì¥í•  ìœ„ì¹˜
            args = vars(ap.parse_args())
            
            API_KEY = "INSERT_YOUR_API_KEY_HERE" #APIì—ì„œ ë°›ì€ KETê°’ ë„£ì–´ì¤€ë‹¤
            MAX_RESULTS = 400 #ì´ ë‚´ê°€ ë‹¤ìš´ë°›ì„ imageê°œìˆ˜
            GROUP_SIZE = 50 #pageë‹¹ 50ê°œì˜ ì´ë¯¸ì§€
            URL = "https://api.cognitive.microsoft.com/bing/v7.0/images/search" #bingì›¹ ë¸Œë¼ìš°ì €ì—ì„œ image/searchì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰í•˜ëŠ” ê²ƒ
            
            ''' ìƒëµ '''
            # make the search
            print("[INFO] searching Bing API for '{}'".format(term))
            search = requests.get(URL, headers=headers, params=params) #ê²€ìƒ‰ ì‹œì‘
            search.raise_for_status()
            # grab the results from the search, including the total number of
            # estimated results returned by the Bing API
            results = search.json() 
            estNumResults = min(results["totalEstimatedMatches"], MAX_RESULTS)
            print("[INFO] {} total results for '{}'".format(estNumResults,
                term))
    
        $ mkdir dataset/blue_jeans
        $ python search_bing_api.py --query "blue jeans" --output dataset/blue_jeans -> ì´ëŸ°ì‹ìœ¼ë¡œ ëª…ë ¹ì–´ ì…ë ¥í•´ì„œ ì´ë¯¸ì§€ datasetë‹¤ìš´ë°›ëŠ”ë‹¤

    ì´ ëª¨ë“ˆì„ ì´ìš©í•´ì„œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì˜·ì˜ datasetì„ êµ¬ì¶•í•´ì•¼ëœë‹¤.
    
3. smallVGGNetì„ ìš°ë¦¬ì˜ datasetìœ¼ë¡œ í•™ìŠµ ì‹œí‚¤ê¸°

    3-1. ì‚¬ì „ ì¤€ë¹„
    
    |êµ¬ë¶„|ê°€ìƒí™˜ê²½ name|CUDA ë²„ì „|NVIDA|CUDNN|Python ë²„ì „|Tensorflow ë²„ì „|Keras ë²„ì „| ì¶”ê°€ ì„¤ì¹˜í•  ë¼ì´ë¸ŒëŸ¬ë¦¬|
    |----|----|------|---|---|---|---|---|---|
    |í•™êµì»´1(íš¨ì„­)|py356|CUDA 10.1|418.x|CUDNN7.6.4|3.7.7 ë²„ì „|2.2|2.4.3| openCV(opencv-python), request, matplotlib, numpy, imutils, sklearn
    |í•™êµì»´1(ì£¼ì˜)|paper|CUDA 10.1|418.x| ?? |3.7.7 ë²„ì „|2.0| 2.1.3| openCV(opencv-python), request, matplotlib, numpy, imutils, sklearn
    
    //conda installë¡œ ì•ˆë˜ëŠ”ê±´ pip install ì‚¬ìš©<br>
    3-2. train.py
    
        EPOCHS = 75    
        INIT_LR = 1e-3  #learning rateë¡œ 1e-3ê°’ì€ Adam optimizer
        BS = 32 #batch sizeê°’
        IMAGE_DIMS = (96, 96, 3) #imageëŠ” 96*96ì— 3ê°œì˜ channel(r,g,b)í¬í•¨í•¨
        
        # ì´ë¶€ë¶„ë“¤ì€ image datasetì„ loadingí•˜ê³  loading datasetë“¤ ëœë¤ìœ¼ë¡œ ì„ìŒ[loadingí•œ datasetë“¤ì€ ê° ì¹´í…Œê³ ë¦¬ í´ë”ì— ì €ì¥ë˜ì–´ ìˆì–´ ì´ê²ƒì„ shuffleí•œë‹¤ëŠ” ì˜ë¯¸]
        print("[INFO] loading images...")
        imagePaths = sorted(list(paths.list_images(args["dataset"])))
        random.seed(42)
        random.shuffle(imagePaths)

        # initialize the data and labels
        data = []
        labels = []
        
        # ImagePaths(loadingí•œ datasetì•ˆì— í´ë”ë“¤)ëŒë©´ì„œ ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì • ì§„í–‰í•˜ê³  multi-class-labelsì¶”ì¶œ!!
        for imagePath in imagePaths:
            image = cv2.imread(imagePath)
            image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0])) #imageëŠ” 96*96ì‚¬ì´ì¦ˆë¡œ resize
            image = img_to_array(image) #image -> array
            data.append(image) #image ì •ë³´[arrayë¡œ ì´ë£¨ì–´ì ¸ìˆìŒ]ë¥¼ dataì— ë„£ê¸°

            #ìš°ë¦¬ëŠ” datasetì•ˆì— í´ë”ë“¤ ì´ë¦„ì„ "color_ì˜·ì¹´í…Œê³ ë¦¬ëª…"ìœ¼ë¡œ ì§€ì •í•˜ì˜€ë‹¤ [ex "red_longDress"] => ë”°ë¼ì„œ _ë¥¼ ê¸°ì¤€ìœ¼ë¡œ splití•˜ë©´ ì•ì—ëŠ” color ë’¤ì—ëŠ” ì¹´í…Œê³ ë¦¬ì´ë¦„ì„  multi-labelë¡œ ì§€ì •í•  ìˆ˜ ìˆë‹¤
            l = label = imagePath.split(os.path.sep)[-2].split("_") 
            labels.append(l) # labels = [("red","longDress"),("blue","jeans")]ì´ëŸ°ì‹ìœ¼ë¡œ ì €ì¥ë¨
            
        # dataì˜ arrayì˜ ê°’ì„ ëª¨ë‘ [0, 1]ë¡œ ì •ê·œí™”í•˜ëŠ” ê³¼ì • [ê°’ì´ í¬ë©´ ê³„ì‚°ëŸ‰ í¬ê¸° ë•Œë¬¸ì— -> ì •ê·œí™”ë¥¼ í•´ì„œ ê³„ì‚° ê°„ë‹¨ ë° ê³„ì‚°ëŸ‰ ì¤„ì„]
        data = np.array(data, dtype="float") / 255.0 # array -> numpy array[ì •ê·œí™”í•œ (0,1)]
        labels = np.array(labels) #label -> numpy arrayë¡œ ë³€í™˜
        print("[INFO] data matrix: {} images ({:.2f}MB)".format(len(imagePaths), data.nbytes / (1024 * 1000.0)))
        
        
        # scikit-learn libraryâ€™sì˜ MultiLabelBinarizerë¥¼ ì‚¬ìš©í•´ì„œ multi labelì„ ë¶„ë¥˜í•œë‹¤ 
        """
            ì˜ˆì œ  labels=[("red","longDress"),("blue","jeans"), ("blue", "longDress"),("red","jeans")]ì´ë©´
            mlb.classes_
                >> array(['red'.'blue','longDress','jeans'], dtype=object)
            mlb.fit_transform([('red', 'jeans')])
                >> array([[1,0,0,1]])
                
        """
        print("[INFO] class labels:")
        mlb = MultiLabelBinarizer()
        labels = mlb.fit_transform(labels) #two-hot encoding ì‚¬ìš©(two-hot encodingì€ 1ì´ ë‘ë²ˆ ë‚˜ì˜¤ê¸° ë•Œë¬¸)

        # loop over each of the possible class labels and show them
        for (i, label) in enumerate(mlb.classes_):
            print("{}. {}".format(i + 1, label))

        # dataì˜ 80%ëŠ” traingìš©, 20%ëŠ” testìš©
        (trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)
        #Kerasì—ì„œ ì œê³µí•˜ëŠ” íŒ¨í‚¤ì§€ "ImageDataGenerator"ë¡œ image dataí•™ìŠµì„ ì‰½ê²Œí•˜ë„ë¡ í•´ì¤€ë‹¤
        """
            ImageDataGenerator classë¥¼ í†µí•´ ê°ì²´ ìƒì„±í• ë•Œ íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬ -> ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‰½ê²Œ í•  ìˆ˜ ìˆë‹¤ => [ì´ë¯¸ì§€ë¥¼ ì›€ì§ì—¬ 1ì¥ì˜ ì‚¬ì§„ì„ ì›€ì§ì—¬ ì—¬ëŸ¬ì¥ì˜ ì‚¬ì§„ ëŠ˜ë¦¬ê¸° => ì‘ì€ ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  í° ë°ì´í„°ì…‹ìœ¼ë¡œ ëŠ˜ë¦¬ëŠ” ë°©ë²•ì´ë¼ê³  ìƒê°í•˜ê¸° => classë‹¹ 1000ê°œë³´ë‹¤ ì ì€ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì¼ ê²½ìš° íš¨ìœ¨ì ì„]
            ğŸ‘‰[ì°¸ê³ ì‚¬ì´íŠ¸1](https://m.blog.naver.com/PostView.nhn?blogId=isu112600&logNo=221582003889&proxyReferer=https:%2F%2Fwww.google.com%2F )
            ğŸ‘‰[ì°¸ê³ ì‚¬ì´íŠ¸2](https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/)
            
            width_shift_range = ì´ë¯¸ì§€ë¥¼ ì™¼ìª½ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì›€ì§ì¸ë‹¤
            height_shift_range =  ì´ë¯¸ì§€ë¥¼ ì•„ë˜, ìœ„ë¡œ ì›€ì§ì¸ë‹¤
            horizontal_flip = ì´ë¯¸ì§€ë¥¼ ìœ„, ì•„ë˜ë¡œ ë’¤ì§‘ëŠ”ë‹¤
            rotation_range = ì´ë¯¸ì§€ë¥¼ ëœë¤ìœ¼ë¡œ íšŒì „ì‹œí‚¨ë‹¤
            zoom_range = ì´ë¯¸ì§€ë¥¼ zoomí•œë‹¤
            shear_range = ì´ë¯¸ì§€ë¥¼ ì „ë‹¨ ë³€í™˜í•œë‹¤
        """
        aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,
            height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
            horizontal_flip=True, fill_mode="nearest")
           
        
        # smallerVGGNet ëª¨ë¸ buildí•œë‹¤[ëª¨ë¸ì€ /paimage/SmallerVGGNet.pyì— ì¡´ì¬]
        #finalAct="sigmoid" => í™œì„±í™” í•¨ìˆ˜ë¡œ "sigmod"í•¨ìˆ˜ ì„¤ì • => multi-label ë¶„ë¥˜ì—ì„œëŠ” í™œì„±í™” í•¨ìˆ˜ë¡œ sigmodë¥¼ ì‚¬ìš©í•œë‹¤
        ğŸ‘‰[ì°¸ê³ ì‚¬ì´íŠ¸3](https://www.kaggle.com/c/imet-2019-fgvc6/discussion/89823)
        ğŸ‘‰[optimizer ì„¤ëª…1](https://forensics.tistory.com/28)
        ğŸ‘‰[optimizer ì„¤ëª…2] (https://wikidocs.net/36033)
        print("[INFO] compiling model...")
        model = SmallerVGGNet.build(
            width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],
            depth=IMAGE_DIMS[2], classes=len(mlb.classes_),
            finalAct="sigmoid")
        # optimizer Adam ì‚¬ìš©
        opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS) #decay: learning rate scheduleì´ë‹¤
        
        
        # ëª¨ë¸ êµ¬ì„±í•œë‹¤(compile)
        # loss functionìœ¼ë¡œ binary_crossentropy ì‚¬ìš© => ê° ì¶œë ¥ ë ˆì´ë¸”ì„ ë…ë¦½ì  ì¸ Bernoulli ë¶„í¬ë¡œ ì·¨ê¸‰í•˜ëŠ” ê²ƒì´ë¯€ë¡œ ê° ì¶œë ¥ ë…¸ë“œì— ë…ë¦½ì ìœ¼ë¡œ ë¶ˆì´ìµì£¼ê¸° ìœ„í•´
        ## ë‹¤ì‹œ ê³µë¶€ ì´í•´ x ì™œ categorical cross-entropy ì‚¬ìš©ì•ˆí•˜ëŠ”ì§€ ì´í•´ x 
        model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])

        # ëª¨ë¸ í›ˆë ¨(fit)
        print("[INFO] training network...")
        H = model.fit_generator(
            aug.flow(trainX, trainY, batch_size=BS),
            validation_data=(testX, testY),
            steps_per_epoch=len(trainX) // BS,
            epochs=EPOCHS, verbose=1)
         
        #ëª¨ë¸ ì €ì¥ -> kerasëŠ” h5ëª¨ë¸ë¡œ ì €ì¥ë¨(ì°¸ê³ )
        print("[INFO] serializing network...")
        model.save(args["model"])
        
        # mlb.labelbin pickleíŒŒì¼ ìƒì„± => ìœ„ì—ì„œ ë§Œë“  mlb classë‚´ìš©ì„ ì €ì¥í•˜ê³  classifyì—ì„œ ì–´ë–¤ labelì— í•´ë‹¹ë˜ëŠ”ì§€ í™•ì¸ì‘ì—…ì„ ìœ„í•´ì„œ í•„ìš”
        print("[INFO] serializing label binarizer...")
        f = open(args["labelbin"], "wb")
        f.write(pickle.dumps(mlb))
        f.close()
        
        
        # ì´ë¶€ë¶„ì€ ì´ì œ ë‚´ê°€ í›ˆë ¨ ê³¼ì •ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•´ matplotlibë¥¼ ì‚¬ìš©í•¨ -> í•„ìš” -> ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ëŠ” ê²ƒì´ ë” ì •í™•í•¨
        # í˜„ì¬ ì´ë¶€ë¶„ ì˜¤ë¥˜ ìˆëŠ”ë° ë³€ìˆ˜ ëª… ì˜¤ë¥˜ì¸ ë“¯ 
        plt.style.use("ggplot")
        plt.figure()
        N = EPOCHS
        plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
        plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
        plt.plot(np.arange(0, N), H.history["acc"], label="train_acc") #ì´ë¶€ë¶„ ì˜¤ë¥˜ acc ì•„ë‹˜ accuracyì„ ìˆ˜ì •í• ê²ƒ
        plt.plot(np.arange(0, N), H.history["val_acc"], label="val_acc")
        plt.title("Training Loss and Accuracy")
        plt.xlabel("Epoch #")
        plt.ylabel("Loss/Accuracy")
        plt.legend(loc="upper left")
        plt.savefig(args["plot"])

        
        $ python train.py --dataset ./dataset --model fashion.model --labelbin mlb.pickle
        
4. ì˜· ë¶„ë¥˜í•˜ê¸° => ì˜· ì˜ˆì¸¡í•˜ëŠ” ë¶€ë¶„

    4-1. classify.py
        
        # ì˜· ë¶„ë¥˜í•˜ë ¤ëŠ” ì‚¬ì§„ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„
        image = cv2.imread(args["image"])
        output = imutils.resize(image, width=400)
        
        # trainì—ì„œ image ì „ì²˜ë¦¬ í•˜ëŠ” ê²ƒê³¼ ê°™ì´ ë˜‘ê°™ì´ setting
        image = cv2.resize(image, (96, 96))
        image = image.astype("float") / 255.0
        image = img_to_array(image)
        image = np.expand_dims(image, axis=0)
        
        # modelì´ë‘ label ì €ì¥í•œê±° ë¶ˆëŸ¬ì˜¤ê¸°
        print("[INFO] loading network...")
        model = load_model(args["model"])
        mlb = pickle.loads(open(args["labelbin"], "rb").read())
        
        # model.predict -> ë‚´ imageíŒŒì¼ì„ ëª¨ë¸ì˜ inputìœ¼ë¡œ ë„£ì–´ ì–´ë–¤ ìƒ‰ê³¼ ì¹´í…Œê³ ë¦¬ì¸ì§€ ì˜ˆì¸¡
        # ì˜ˆì¸¡ ê²°ê³¼ëŠ” array([[1,0,0,1]]) ì´ëŸ° ê²ƒì²˜ëŸ¼ two-hot encodingëœ array ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤. 1ì´ ë“¤ì–´ê°„ indexìœ„ì¹˜ë¥¼ ì–»ì–´ idxsì— ë„£ëŠ”ë‹¤
        print("[INFO] classifying image...")
        proba = model.predict(image)[0]
        idxs = np.argsort(proba)[::-1][:2]

        # ì´ë¶€ë¶„ í•„ìš” ì—†ìŒ -> ì‚¬ì§„ì— ë­ë‘ ë­ê°€ ë†’ì¸ì§€ ë„ì–´ì¦ˆëŠ” ê±° ë¿
        for (i, j) in enumerate(idxs):
        # build the label and draw the label on the image
        label = "{}: {:.2f}%".format(mlb.classes_[j], proba[j] * 100)
        cv2.putText(output, label, (10, (i * 30) + 25), 
            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
        # ê° labelë“¤ì— ëŒ€í•´ ëª‡ %ë¡œ ë†’ì€ì§€ ì¶œë ¥í•´ì¤Œ -> ì´ê²Œ í•„ìš” ì˜· ë¶„ë¥˜í•˜ëŠ” ê±°ë‹ˆê¹Œ
        for (label, p) in zip(mlb.classes_, proba):
            print("{}: {:.2f}%".format(label, p * 100))
            
        # í•„ìš” x
        cv2.imshow("Output", output)
        cv2.waitKey(0)
        
        
        $ python classify.py --model fashion.model --labelbin mlb.pickle --image examples/example_01.jpg
